# -*- coding: utf-8 -*-
"""Copy of Forest Model (Jayden, Abby)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ix7EA773OCBwMejS45qpej-GLxtnhYVY
"""

# This project is for "Detecting Credit Card Fraud."

# Dataset: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

"""#Imports:

"""

# Commented out IPython magic to ensure Python compatibility.
#Add import
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import os
import joblib

import math
import json
from pathlib import Path
import kagglehub
import os
import shutil
from datetime import datetime

from scipy.stats import zscore
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import plotly.graph_objects as go



from sklearn.preprocessing import PowerTransformer, LabelEncoder

from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import TomekLinks
from imblearn.combine import SMOTETomek

from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import (
    RandomForestClassifier,
    GradientBoostingClassifier,
    AdaBoostClassifier,
)
from sklearn.svm import SVC
from xgboost import XGBClassifier

from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    classification_report,
    confusion_matrix,
    roc_auc_score,
    make_scorer
)

import shap

import warnings
warnings.filterwarnings('ignore')

"""#Loading and cleaning the Dataset

Load the Dataset
'/content/creditcard.csv'
*Make sure fraudTest.csv is in the Files on the left side*
"""

file_path = '/content/creditcard.csv'

data = pd.read_csv(file_path)
#print(file_path)

"""Data Cleaning the csv = Remove duplicates, Drop rows with 0 values, remove outliers, and Normalization."""

# def clean_dataset(file_path):
#     # Load the dataset
#     data = pd.read_csv(file_path)

#     # Check for and remove duplicates
#     if data.duplicated().any():
#         data = data.drop_duplicates()
#         print("Duplicates removed.")
#     else:
#         print("No duplicates found.")

#     # Return the cleaned dataset
#     return data

# File path
file_path = '/content/creditcard.csv'

# Call the function and clean the data
# cleaned_data = clean_dataset(file_path)

print(data)
# cleaned_data.head()

"""#Get Statistics on cleaned Data
Including the distribution between fraud and non fraud
"""

# Ensure 'cleaned_data' is a valid DataFrame
df = data.copy()

# Ensure the target variable is binary (if not already)
# Convert target to 0 and 1, assuming valid binary values might have been mis-transformed
df['Class'] = df['Class'].apply(lambda x: 1 if x > 0 else 0)

# Separate features (X) and target (y)
X = df.drop('Class', axis=1)
y = df['Class']

# Split the data into train and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Verify the distribution in training and testing sets
print(f"Training set fraud percentage: {y_train.mean() * 100:.2f}%")
print(f"Test set fraud percentage: {y_test.mean() * 100:.2f}%")

# Check detailed distribution in training set
print("Training set fraud distribution:")
print(y_train.value_counts(normalize=True) * 100)

# Check detailed distribution in test set
print("Test set fraud distribution:")
print(y_test.value_counts(normalize=True) * 100)

# Confirm unique values in the target variable
print("Unique values in target variable:", y.unique())

# Optional: Display the first few rows of cleaned data
data.head()

# Count the total number of fraud and non-fraud cases
fraud_counts = data['Class'].value_counts()
print("Number of fraud and non-fraud cases:")
print(fraud_counts)

# Extract the number of fraud cases
num_fraud = fraud_counts.get(1, 0)  # Assuming fraud is encoded as '1'
num_non_fraud = fraud_counts.get(0, 0)  # Assuming non-fraud is encoded as '0'
print(f"Fraud cases: {num_fraud}")
print(f"Non-fraud cases: {num_non_fraud}")

# Calculate the percentage of fraud cases
total_cases = len(data)
fraud_percentage = (num_fraud / total_cases) * 100
print(f"Percentage of fraud cases: {fraud_percentage:.2f}%")

# Optionally: Filter the rows where is_fraud == 1
fraud_cases = data[data['Class'] == 1]
print("Example fraud cases:")
print(fraud_cases.head())

#Correlation matrix:
df = data.copy()
# Compute the correlation matrix
corr_matrix = df.corr()
corr_matrix = corr_matrix.T

# Print the correlation matrix
# print("Correlation Matrix:\n", corr_matrix)

# Visualize the correlation matrix using a heatmap
plt.figure(figsize=(20, 20))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Matrix Heatmap")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# Load dataset (Replace with actual data)
data = data.copy()
# Compute correlation matrix
correlation_matrix = data.corr()
# Transpose the matrix to flip it vertically
correlation_matrix = correlation_matrix.T  # Transpose for vertical effect
# Set figure size for a tall layout
plt.figure(figsize=(6, 12))  # Adjust width and height
# Create heatmap with vertical red-to-blue gradient
sns.heatmap(
    correlation_matrix,
    cmap="RdBu_r",  # Red-to-Blue color map
    annot=True,      # Show values
    fmt=".2f",       # Format decimal places
    linewidths=0.5,  # Add gridlines
    center=0,        # Set midpoint for better contrast
    cbar_kws={'orientation': 'horizontal'}  # Makes color bar horizontal
)
# Set title
plt.title("Vertical Credit Card Fraud Correlation Heatmap", fontsize=14)
# Rotate x-axis labels for readability
plt.xticks(rotation=90)
# Show plot
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import networkx as nx
# Load dataset (Replace with actual data)
data = data.copy()
# Compute correlation matrix
correlation_matrix = data.corr()
# Create a graph from the correlation matrix
G = nx.Graph()
# Add nodes (features)
for feature in correlation_matrix.columns:
    G.add_node(feature)
# Add edges based on correlation values
for i in range(len(correlation_matrix.columns)):
    for j in range(i+1, len(correlation_matrix.columns)):  # Avoid duplicate edges
        corr_value = correlation_matrix.iloc[i, j]
        if abs(corr_value) > 0.3:  # Threshold for visibility
            G.add_edge(
                correlation_matrix.columns[i],
                correlation_matrix.columns[j],
                weight=abs(corr_value)
            )
# Draw circular layout
plt.figure(figsize=(10, 10))
pos = nx.circular_layout(G)  # Arrange nodes in a circle
# Draw nodes and edges
nx.draw(G, pos, with_labels=True, node_size=3000, edge_color='gray', font_size=10, font_color='black')
# Draw edges with varying thickness based on correlation strength
edges = nx.get_edge_attributes(G, 'weight')
nx.draw_networkx_edges(G, pos, width=[v * 5 for v in edges.values()], edge_color=list(edges.values()), edge_cmap=plt.cm.RdBu_r)
# Show plot
plt.title("Circular Credit Card Fraud Correlation Map")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset (Replace with actual dataset)
df = data.copy()  # Ensure your dataset has a "Fraud" column

# Compute correlation matrix
corr_matrix = df.corr()

# Extract correlations with the target variable "Fraud"
fraud_corr = corr_matrix["Class"].drop("Class").sort_values(ascending=False)

# Convert to DataFrame for easier visualization
fraud_corr_df = pd.DataFrame(fraud_corr).reset_index()
fraud_corr_df.columns = ["Variable", "Correlation"]

# Plot heatmap
plt.figure(figsize=(3, 12))  # Narrow figure for vertical layout
ax = sns.heatmap(fraud_corr_df.set_index("Variable"),
                 annot=True,
                 cmap="coolwarm",
                 cbar=True,
                 linewidths=0.5)

# Adjust plot aesthetics
plt.title("Correlation Heatmap: Correlation between Variables (Columns) and Fraud")
plt.xticks(rotation=0)
plt.show()

import matplotlib.pyplot as plt

df = data.copy()
plt.figure(figsize=(8, 6))
plt.scatter(df['Amount'], df['V11'], c=df['Class'])
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Scatter Plot of Data Points Colored by Fraud')
plt.colorbar(label='Fraud')
plt.show()

df.Class.value_counts().plot(kind='bar')
import matplotlib.pyplot as plt
import numpy as np

counts = df.Class.value_counts()
custom_labels = ['Non-Fraud', 'Fraud']
categories = np.arange(len(counts))
colors = ['#89d0e9ff', '#a869e7ff']

plt.figure(figsize=(6, 8))  # Adjust the height for better visibility

plt.bar(counts.index, counts.values, color=colors)
plt.title('Non-Fraud Vs. Fraud')
for i, v in enumerate(counts):
    plt.text(i, v + 0.5, str(v), ha='center', va='bottom', fontsize=12)
# Add value labels above bars
plt.xticks(categories, custom_labels, rotation=0)
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()

"""#Random Forest Classifier - Imbalanced

"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()



"""#Dealing with Imbalanced data:

#SMOTE
Conclusion:
Decent, not horrible, a bit of improvement but not much.
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE

# Copy data
df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Apply SMOTE to the training data only
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Train the RandomForestClassifier on the resampled data
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_resampled, y_train_resampled)

# Test on the original unbalanced test set
y_pred = rf_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Calculate and plot confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

"""
#Random Over Sampler

#Conclusion:
Amazing results, but at what cost? It's almost toooooo good..."""

# deal with imbalanced data: RANDOM OVER SAMPLER
import numpy as np
from sklearn.datasets import make_classification
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from collections import Counter


df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

# Oversampling using RandomOverSampler
oversample = RandomOverSampler(sampling_strategy='minority')
X_over, y_over = oversample.fit_resample(X, y)
print("Oversampled class distribution:", Counter(y_over))

X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)

rf_model = RandomForestClassifier(n_estimators=45, random_state=42)
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)


# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

#CONCLUSION:
# Amazing results, but at what cost? It's almost toooooo good...

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from imblearn.over_sampling import RandomOverSampler
from collections import Counter
import matplotlib.pyplot as plt

# Assuming 'data' is your original dataset
df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

# Split the data into training and testing sets before oversampling
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Oversampling using RandomOverSampler, only on training data
oversample = RandomOverSampler(sampling_strategy='minority')
X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)
print("Oversampled class distribution in training set:", Counter(y_train_over))

# Train the model using the oversampled training data
rf_model = RandomForestClassifier(n_estimators=45, random_state=42)
rf_model.fit(X_train_over, y_train_over)

# Predict on the original test data (no oversampling)
y_pred = rf_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

"""#Random Under Sampler:

#Conclusion:
Better f1-score for the minority class, but lower f1-score for the majority class
"""

# Undersampling using RandomUnderSampler
# Assuming 'data' is your original dataset
df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

undersample = RandomUnderSampler(sampling_strategy='majority')
X_under, y_under = undersample.fit_resample(X, y)
print("Undersampled class distribution:", Counter(y_under))

X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)

rf_model = RandomForestClassifier(n_estimators=45, random_state=42)
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)


# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))


# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

#CONCLUSION:
#Better f1-score for the minority class, but lower f1-score for the majority class

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from imblearn.under_sampling import RandomUnderSampler
from collections import Counter
import matplotlib.pyplot as plt

# Assuming 'data' is your original dataset
df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

# Split the data into training and testing sets before undersampling
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Undersampling using RandomUnderSampler, only on training data
undersample = RandomUnderSampler(sampling_strategy='majority')
X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)
print("Undersampled class distribution in training set:", Counter(y_train_under))

# Train the model using the undersampled training data
rf_model = RandomForestClassifier(n_estimators=45, random_state=42)
rf_model.fit(X_train_under, y_train_under)

# Predict on the original test data (no undersampling)
y_pred = rf_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

#CONCLUSION:
# The undersampling has led to a better f1-score for the majority class, but possibly a lower f1-score for the minority class.

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from collections import Counter

df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=.2, random_state=42)

# Apply SMOTE to oversample the minority class
smote = SMOTE(sampling_strategy='minority', random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("Original class distribution:", Counter(y_train))
print("New class distribution after SMOTE:", Counter(y_train_resampled))

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_resampled, y_train_resampled)
y_pred = rf_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

"""#testing

"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from matplotlib.animation import FuncAnimation

def update(frame):  # Define update here, before other code blocks
        ax.clear()
        sns.heatmap(conf_matrices[frame], annot=True, cmap="Blues", fmt="d", cbar=False, ax=ax)
        ax.set_title(f"Confusion Matrix at {int(increments[frame] * 100)}% Training Data")


# Drop NaNs from dataset (Fix NaN issue)
df = data.dropna(subset=['Class']).copy()

X = df.drop('Class', axis=1)
y = df['Class']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Drop NaNs from y_test and align with X_test
y_test = y_test.dropna()
X_test = X_test.loc[y_test.index]  # Ensure indexes match

# Define training increments
increments = np.linspace(0.1, 1.0, 10)  # 10 steps
conf_matrices = []

# Train model incrementally and store confusion matrices
for frac in increments:
    sample_size = int(frac * len(X_train))
    X_train_frac = X_train.iloc[:sample_size]
    y_train_frac = y_train.iloc[:sample_size]

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_frac, y_train_frac)

    # Predict and compute confusion matrix
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    conf_matrices.append(cm)

# Fix figure setup
fig, ax = plt.subplots(figsize=(6, 6))
sns.heatmap(conf_matrices[0], annot=True, cmap="Blues", fmt="d", cbar=False, ax=ax)

def update(frame):
    ax.clear()
    sns.heatmap(conf_matrices[frame], annot=True, cmap="Blues", fmt="d", cbar=False, ax=ax)
    ax.set_title(f"Confusion Matrix at {int(increments[frame] * 100)}% Training Data")

# Create animation
ani = FuncAnimation(fig, update, frames=len(conf_matrices), repeat=True, interval=1000)

plt.show()

"""#Other models

"""

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from collections import Counter

df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

log = LogisticRegression()
log.fit(X_train, y_train)
y_pred = log.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from collections import Counter

df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

# Apply SMOTE to oversample the minority class
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("Original class distribution:", Counter(y_train))
print("New class distribution after SMOTE:", Counter(y_train_resampled))

log = LogisticRegression()
log.fit(X_train_resampled, y_train_resampled)
y_pred = log.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Generate an imbalanced dataset
from sklearn.datasets import make_classification

df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

print("Original class distribution:", Counter(y))

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

# Apply SMOTE to balance the dataset
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("Resampled class distribution:", Counter(y_train_resampled))

# Standardize the dataset
scaler = StandardScaler()
X_train_resampled = scaler.fit_transform(X_train_resampled)
X_test = scaler.transform(X_test)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_resampled, y_train_resampled)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
# Create and plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

"""#Model cross-evaluation

"""

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score, KFold, cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import lightgbm as lgb
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import confusion_matrix, classification_report
from imblearn.over_sampling import SMOTE

# Load dataset
df = data.copy()
X = df.drop('Class', axis=1)
y = df['Class']

# Apply SMOTE to handle imbalanced data for training
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_resampled)
X_original_scaled = scaler.transform(X)  # Keep original test data standardized

# Define models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "LightGBM": lgb.LGBMClassifier(n_estimators=100, random_state=42)
}

# Cross-validation setup
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Evaluate models
results = {}
for name, model in models.items():
    scores = cross_val_score(model, X_scaled, y_resampled, cv=kf, scoring='accuracy')
    results[name] = scores
    print(f"{name}: Mean Accuracy (Balanced) = {scores.mean():.4f}, Std = {scores.std():.4f}")

    # Train on balanced data, test on original unbalanced data
    model.fit(X_scaled, y_resampled)
    y_pred = model.predict(X_original_scaled)

    # Compute confusion matrix and classification report
    cm = confusion_matrix(y, y_pred)
    cr = classification_report(y, y_pred)

    print(f"Confusion Matrix for {name} (Tested on Unbalanced Data):\n{cm}\n")
    print(f"Classification Report for {name} (Tested on Unbalanced Data):\n{cr}\n")

import matplotlib.pyplot as plt
import matplotlib.animation as animation
import numpy as np
import pandas as pd
import matplotlib
matplotlib.rcParams['animation.embed_limit'] = 2**128

# Load dataset
df = pd.read_csv("creditcard.csv")  # Ensure the file is in the same directory

# Use all fraud cases & match with non-fraud cases
df_fraud = df[df["Class"] == 1]  # Take ALL fraud cases
df_non_fraud = df[df["Class"] == 0].sample(len(df_fraud), random_state=42)  # Match fraud count

# Combine and sort by time
df_sample = pd.concat([df_fraud, df_non_fraud]).sort_values(by="Time")

# Extract time, amount, and class labels
time_data = df_sample["Time"].values
amount_data = df_sample["Amount"].values
labels = df_sample["Class"].values

# Define a colormap: 0 (non-fraud) → blue, 1 (fraud) → red
cmap = plt.cm.get_cmap("coolwarm")
norm = plt.Normalize(vmin=0, vmax=1)

# Initialize the figure and axis
fig, ax = plt.subplots(figsize=(8, 5))
ax.set_xlim(time_data.min(), time_data.max())
ax.set_ylim(amount_data.min(), amount_data.max())
ax.set_xlabel("Time")
ax.set_ylabel("Amount")
ax.set_title("Transaction Scatter Plot (Fraud in Red, Non-Fraud in Blue)")

# Initialize empty scatter plot with colormap
scatter = ax.scatter([], [], c=[], cmap=cmap, norm=norm, alpha=0.6)

# Update function for animation
def update(frame):
    scatter.set_offsets(np.c_[time_data[:frame], amount_data[:frame]])  # Update points
    scatter.set_array(labels[:frame])  # Assign labels dynamically for colors
    return scatter,

# Create animation
ani = animation.FuncAnimation(fig, update, frames=len(time_data), interval=10, blit=False)

# Display animation inline
from IPython.display import HTML
HTML(ani.to_jshtml())